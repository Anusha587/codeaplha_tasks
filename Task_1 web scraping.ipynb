{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fba042f-5753-43af-bc7b-b32c6c5a4107",
   "metadata": {},
   "source": [
    "# Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1127a54-0b92-4583-8577-551e82fdbdd3",
   "metadata": {},
   "source": [
    "# used Python with BeautifulSoup to extract top news headlines from a website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62a75108-3124-4ee0-be12-07c91ce6612a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. GrapheneOS – Break Free from Google and Apple (blog.tomaszdunia.pl)\n",
      "2. Four Column ASCII (2017) (garbagecollected.org)\n",
      "3. 14-year-old Miles Wu folded origami pattern that holds 10k times its own weight (smithsonianmag.com)\n",
      "4. How teaching molecules to think is revealing what a 'mind' is (newscientist.com)\n",
      "5. Rise of the Triforce (dolphin-emu.org)\n",
      "6. Show HN: Glitchy camera – a circuit-bent camera simulator in the browser (glitchycam.com)\n",
      "7. Rendering the Visible Spectrum (brandonli.net)\n",
      "8. A deep dive into Apple's .car file format (dbg.re)\n",
      "9. Poor Deming never stood a chance (surfingcomplexity.blog)\n",
      "10. What your Bluetooth devices reveal (dmcc.io)\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://news.ycombinator.com/\"\n",
    "response = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "titles = soup.find_all(\"span\", class_=\"titleline\")\n",
    "\n",
    "for i, title in enumerate(titles[:10]):\n",
    "    print(f\"{i+1}. {title.text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ce48743-9179-4066-8194-7b4c6afdd6dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. GrapheneOS – Break Free from Google and Apple (blog.tomaszdunia.pl)\n",
      "2. Four Column ASCII (2017) (garbagecollected.org)\n",
      "3. 14-year-old Miles Wu folded origami pattern that holds 10k times its own weight (smithsonianmag.com)\n",
      "4. How teaching molecules to think is revealing what a 'mind' is (newscientist.com)\n",
      "5. Rise of the Triforce (dolphin-emu.org)\n",
      "6. Show HN: Glitchy camera – a circuit-bent camera simulator in the browser (glitchycam.com)\n",
      "7. Rendering the Visible Spectrum (brandonli.net)\n",
      "8. A deep dive into Apple's .car file format (dbg.re)\n",
      "9. Poor Deming never stood a chance (surfingcomplexity.blog)\n",
      "10. What your Bluetooth devices reveal (dmcc.io)\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://news.ycombinator.com/\"\n",
    "response = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "titles = soup.find_all(\"span\", class_=\"titleline\")\n",
    "\n",
    "for i, title in enumerate(titles[:10]):\n",
    "    print(f\"{i+1}. {title.text}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493f3889-bea7-43de-9e50-4c7dfbd3eb7f",
   "metadata": {},
   "source": [
    "# handle the html structure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3024b496-efe9-4fb1-80e1-85937066fa5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <head>\n",
      "  <title>\n",
      "   My Page\n",
      "  </title>\n",
      " </head>\n",
      " <body>\n",
      "  <h1>\n",
      "   Hello Anusha\n",
      "  </h1>\n",
      " </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "with open(\"C:/Users/91974/Downloads/anu.txt\", \"r\") as file:\n",
    "    content = file.read()\n",
    "\n",
    "\n",
    "soup = BeautifulSoup(content, \"html.parser\")\n",
    "\n",
    "print(soup.prettify())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d227d25-3a9d-422e-a9a0-c55580a79b82",
   "metadata": {},
   "source": [
    "# Read Specific Title in html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef48552f-b2a2-4fa6-9858-421d8867fde8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>My Page</title>\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "with open(\"C:/Users/91974/Downloads/anu.txt\", \"r\") as file:\n",
    "    content = file.read()\n",
    "\n",
    "\n",
    "soup = BeautifulSoup(content, \"html.parser\")\n",
    "tag=soup.title\n",
    "print(tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b011d7b8-d415-4df5-9c93-2ac03e4f14b8",
   "metadata": {},
   "source": [
    "# modify the html title tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "39c9db94-aa0a-4a1e-ab0e-ed81a8e8895c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>new htlm title </title>\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "with open(\"C:/Users/91974/Downloads/anu.txt\", \"r\") as file:\n",
    "    content = file.read()\n",
    "\n",
    "\n",
    "soup = BeautifulSoup(content, \"html.parser\")\n",
    "tag=soup.title\n",
    "tag.string=\"new htlm title \"\n",
    "print(tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f13abae-4865-42c8-a975-57c07942c3b9",
   "metadata": {},
   "source": [
    "Web scraping is used to automatically collect data from websites instead of copying it manually.\n",
    "It helps in analyzing large amounts of online data like prices, news, or student records quickly.\n",
    "This makes tasks faster, efficient, and useful for data analysis or machine learning projects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30884ad8-f6f2-4e51-9d0d-f509a22a04bf",
   "metadata": {},
   "source": [
    "# Create Custom Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc0f86d-52d3-4774-b509-c67ea0d92db6",
   "metadata": {},
   "source": [
    "# After scraping\n",
    "# Create dataset list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1800c53a-caa1-44cf-8f8b-92c16c33ced6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2a3ca9-c33d-400b-b226-8b647b7ba112",
   "metadata": {},
   "source": [
    "# Extract and store data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a8452c-e2b4-4fea-8a82-6a04d592b3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, title in enumerate(titles[:10]):\n",
    "    text = title.text.strip()\n",
    "    print(f\"{i+1}. {text}\")\n",
    "    \n",
    "    data.append({\n",
    "        \"Rank\": i + 1,\n",
    "        \"Title\": text\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab54315-c70d-4a2e-b8c3-fd88e79ff03b",
   "metadata": {},
   "source": [
    "# Convert to DataFrame (dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a509c4d-7b3b-4e52-ae14-21647ea86027",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95677ac-678f-44a1-bc85-067450d38ba2",
   "metadata": {},
   "source": [
    "# Save dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee51700-9cfb-4568-ad1e-b70922813d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"hackernews_dataset.csv\", index=False)\n",
    "\n",
    "print(\"\\nDataset saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b8e32b-b829-47d8-9e75-d4da6b91e4e6",
   "metadata": {},
   "source": [
    "# final custome datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "023323aa-bae3-4ee6-976f-e77eaf22deac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. GrapheneOS – Break Free from Google and Apple (blog.tomaszdunia.pl)\n",
      "2. Four Column ASCII (2017) (garbagecollected.org)\n",
      "3. 14-year-old Miles Wu folded origami pattern that holds 10k times its own weight (smithsonianmag.com)\n",
      "4. How teaching molecules to think is revealing what a 'mind' is (newscientist.com)\n",
      "5. Rise of the Triforce (dolphin-emu.org)\n",
      "6. Show HN: Glitchy camera – a circuit-bent camera simulator in the browser (glitchycam.com)\n",
      "7. Rethinking High-School Science Fairs (asteriskmag.com)\n",
      "8. Rendering the Visible Spectrum (brandonli.net)\n",
      "9. Poor Deming never stood a chance (surfingcomplexity.blog)\n",
      "10. A deep dive into Apple's .car file format (dbg.re)\n",
      "\n",
      "Dataset saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://news.ycombinator.com/\"\n",
    "response = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "titles = soup.find_all(\"span\", class_=\"titleline\")\n",
    "\n",
    "data = []\n",
    "\n",
    "for i, title in enumerate(titles[:10]):\n",
    "    text = title.text.strip()\n",
    "    print(f\"{i+1}. {text}\")\n",
    "    \n",
    "    data.append({\n",
    "        \"Rank\": i + 1,\n",
    "        \"Title\": text\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df.to_csv(\"hackernews_dataset.csv\", index=False)\n",
    "\n",
    "print(\"\\nDataset saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd22d6a0-eee5-4a00-9cf0-742bf0c32a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Name  Marks  StudyHours\n",
      "0    A     80           5\n",
      "1    B     60           3\n",
      "2    C     90           6\n",
      "3    D     50           2\n",
      "           Marks  StudyHours\n",
      "count   4.000000    4.000000\n",
      "mean   70.000000    4.000000\n",
      "std    18.257419    1.825742\n",
      "min    50.000000    2.000000\n",
      "25%    57.500000    2.750000\n",
      "50%    70.000000    4.000000\n",
      "75%    82.500000    5.250000\n",
      "max    90.000000    6.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    \"Name\": [\"A\", \"B\", \"C\", \"D\"],\n",
    "    \"Marks\": [80, 60, 90, 50],\n",
    "    \"StudyHours\": [5, 3, 6, 2]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df.head())\n",
    "print(df.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f5190b-55ff-4daa-bfce-d71ee2afb0cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
